\subsection{Системы линейных однородных дифференциальных уравнений с постоянными коэффициентами, методы их решения.}

\Def Системой линейных однородных дифференциальных уравнений с постоянными коэффициентами называется система

\begin{equation*}
    \begin{cases}
        x_1' = a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n, \\
        x_2' = a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n, \\
        \dots \\
        x_n' = a_{n1}x_1 + a_{n2}x_2 + \dots + a_{nn}x_n, \\
    \end{cases}
\end{equation*}

или $x' = Ax$, где $A\in Matr_{n \times n}(\R);\; x: I \rightarrow \R^n, I \subset \R$.

\Note Так же, как и в случае одного ЛОДУ с постоянными коэффициентами, множество решений системы ЛОДУ с постоянными коэффициентами является линейным пространством.

\subsubsection{Случай n различных собственных векторов}

\Th Пусть $v_1, \dots, v_n$ -- попарно различные собственные векторы матрицы $A$, соответствующие \textbf{необязательно попарно различным} собственным значениям $\lambda_1, \dots, \lambda_n$.

Тогда общее решение СЛОДУ имеет вид

\begin{equation*}
    x(t) = \sum_{j=1}^n C_j e^{\lambda_j t} v_j,
\end{equation*}

где $C_1, \dots, C_n \in \Cmp$.

\Proof

Так как $v_j$ - собственный вектор $A$ с собственным значением $\lambda_j$, то по определению $A(v_j) = \lambda_j v_j$.

Покажем, что любая функция вида $h(t) = e^{\lambda_j t} v_j$ удовлетворяет системе.

\begin{equation*}
    h' = \frac{d}{dt} (e^{\lambda_j t} v_j) = \lambda_j e^{\lambda_j t} v_j = e^{\lambda_j t} A(v_j) = A(e^{\lambda_j t} v_j) = Ah
\end{equation*}

Теперь покажем, что любое решение $x$ представимо в данном виде.

Обозначим $x_0 \coloneqq x(0)$.
Так как $v_1, \dots, v_n$ -- собственные векторы, соответствующие попарно различным собственным значениям, то они ЛНЗ, а значит образуют базис, по которому можно разложить $x_0$:

\begin{equation*}
    \exists c_1, \dots, c_n \in \Cmp: x_0 = \sum_{k=1}^n c_k v_k.
\end{equation*}

Тогда функция $\hat{x}(t) \coloneqq \sum_{k=1}^n c_k v_k e^{\lambda_k t}$, во-первых, является решением (уже доказано, что любая функция в таком виде является решением), а во-вторых, совпадает с $x$ в точке $0$: $\hat{x}(0) = \sum_{k=1}^n c_k v_k e^{\lambda_k \cdot 0} = \sum_{k=1}^n c_k v_k = x_0 = x(0)$.
Следовательно, по теореме Коши, $x = \hat{x}$, то есть мы нашли представление произвольного решения $x$ в искомом виде.

\Endproof

\Theor{Об овеществлении решений в простейшем случае}

Если

\begin{gather*}
    \lambda_1 = \overline{\lambda_2}, \lambda_3 = \overline{\lambda_4}, \dots, \lambda_{2m-1} = \overline{\lambda_{2m}}; \lambda_{2m+1}, \dots, \lambda_n \in \R, \\
    v_1 = \overline{v_2}, v_3 = \overline{v_4}, \dots, v_{2m-1} = \overline{v_{2m}}; v_{2m+1}, \dots, v_n \in \R^n, \\
    \lambda_j = \alpha_j + i\beta_j, \; v_j = \xi_j + i\mu_j \quad \forall j = 1, \dots, 2m,
\end{gather*}

то общее решение имеет вид

\begin{equation*}
    x(t) = \sum_{k=1}^m e^{\alpha_k t} \left( A_k \left( \xi_k \cos \beta_k t - \mu_k \sin \beta_k t \right) +  B_k \left(\mu_k \cos \beta_k t + \xi_k \sin \beta_k t \right) \right) + \sum_{s=2m+1}^n C_s v_s e^{\lambda_s t},
\end{equation*}

где $A_k, B_k, C_k \in \R$ -- произвольные коэффициенты.

\Note Заметим, что в этом простейшем случае требуется, чтобы нашлось $n$ различных собственных векторов, но вовсе не обязательно должно быть $n$ различных собственных значений.
Например, матрица системы из 2 уравнений может иметь всего одно собственное значение $\lambda$, которому соответствуют два \textbf{различных} собственных вектора $v_1, v_2$.
Тогда мы все еще вправе записать общее решение в виде $x(t) = C_1 e^{\lambda t} v_1 + C_2 e^{\lambda t} v_2$.

А вот если у какого-то из корней алгебраическая кратность не совпадает с геометрической, то есть его кратность как корня характеристического уравнения $(A - \lambda E) = 0$ \textbf{строго больше}, чем количество соответствующих ему собственных векторов, то для нахождения общего решения необходимо использовать Жордановы цепочки, как описано ниже.

\subsubsection{Жорданова нормальная форма}

\Def Векторы $v_1, \dots, v_n$ называются Жордановой цепочкой присоединенных, или обобщенных, векторов к собственному вектору $v_1$ матрицы $A$, соответствующему собственному значению $\lambda$, если

\begin{align*}
    Av_1 &= \lambda v_1, \\
    Av_k &= \lambda v_k + v_{k-1} \quad \forall k = 2, \dots, n, \\
    (A - \lambda E) v &= v_k \text{ не имеет решений (относительно v)}
\end{align*}

\Note Первые две строки можно переписать немного по-другому, возможно понятнее:

\begin{equation*}
    \begin{cases}
        (A - \lambda E) v_1 = 0, \\
        (A - \lambda E) v_2 = v_1, \\
        (A - \lambda E) v_3 = v_2, \\
        \dots \\
        (A - \lambda E) v_n = v_{n-1}
    \end{cases}
\end{equation*}

или

\begin{equation*}
    \begin{cases}
    (A - \lambda E)^1 v_1 = 0, \\
    (A - \lambda E)^2 v_2 = 0, \\
    (A - \lambda E)^3 v_3 = 0, \\
    \dots \\
    (A - \lambda E)^n v_n = 0
    \end{cases}
\end{equation*}

\Thbd Для любой матрицы $A$ существует базис в $\Cmp^n$, называемый Жордановым, состоящий из Жордановых цепочек, соответствующих собственным векторам матрицы $A$.

Причем если $A \in Matr(\R)$, то эти цепочки можно выбрать так, чтобы цепочки, соответствующие действительным собственным значениям, состояли из действительных векторов, а цепочки, соответствующие попарно сопряженным комлексным собственным значениям, состояли из попарно сопряженных комплексных векторов.
В этом базисе преобразование, задаваемое матрицей $A$, будет иметь блочно-диагональную матрицу, называемой нормальной жордановой формой:

\begin{equation*}
    \begin{pmatrix}
          J_{k_1}(\lambda_1) & 0 & \cdots & 0\\[4pt]
          0 & J_{k_2}(\lambda_2) & \ddots & \vdots\\[4pt]
          \vdots & \ddots & \ddots & 0\\[4pt]
          0 & \cdots & 0 & J_{k_m}(\lambda_m)
    \end{pmatrix}
\end{equation*}

Введем обозначения:

Пусть $v_1, \dots, v_n$ -- Жорданов базис, а именно

\begin{align*}
    v_1, \dots, v_{k_1} &\text{ -- Жорданова цепочка, соответствующая собственному значению } \lambda_1, \\
    v_{k_1+1}, \dots, v_{k_1+k_2} &\text{ -- Жорданова цепочка, соответствующая собственному значению } \lambda_2, \\
    v_{k_1+k_2+1}, \dots, v_{k_1+k_2+k_3} &\text{ -- Жорданова цепочка, соответствующая собственному значению } \lambda_3, \\
    \dots \\
    v_{k_1+\dots+k_{n-1}+1}, \dots, v_{k_1+\dots+k_{n-1}+k_n} &\text{ -- Жорданова цепочка, соответствующая собственному значению } \lambda_n. \\
\end{align*}

Тогда:

\begin{align*}
    \begin{cases}
        K_1 \coloneqq 0, \\
        K_2 \coloneqq k_1, \\
        \dots \\
        K_j \coloneqq k_1 + \dots + k_{j-1},
    \end{cases}
\end{align*}

\begin{align*}
    \phi_{K_j+p}(t) \coloneqq \frac{t^{p-1}}{(p-1)!} v_{K_j + 1} + \frac{t^{p-2}}{(p-2)!} v_{K_j + 2} + \dots + \frac{t^1}{1!} v_{K_j + (p-1)} + v_{K_j + p} \qquad \forall j = 1, \dots, l;\; \forall p = 1, \dots, k_j,
\end{align*}

\begin{align*}
    \psi_{K_j + p}(t) \coloneqq \phi_{K_j+p}(t) e^{\lambda_j t}.
\end{align*}

\Th Для введенных функций верны (и доказываются напрямую) следующие утверждения:

\begin{enumerate}
    \item $\phi'_{K_j+p}(t) = \phi_{K_j+p-1}(t)$,
    \item $A\phi_{K_j+p}(t) = \lambda_j \phi_{K_j+p}(t) + \phi_{K_j+p-1}(t)$,
    \item $\psi'_{K_j+p}(t) = \lambda_j \psi_{K_j+p}(t) + \psi_{K_j+p-1}(t)$,
    \item $A\psi_{K_j+p}(t) = \lambda_j \psi_{K_j+p}(t) + \psi_{K_j+p-1}(t)$
\end{enumerate}

(Заметим, что правые части уравнений 3 и 4 равны, то есть $\psi'_{K_j+p}(t) = A\psi_{K_j+p}(t)$)

\Theor{Об общем решении СЛОДУ с постоянными коэффициентами}

Пусть матрица $A$ имеет Жорданов базис, составленный из Жордановых цепочек, как описано в обозначениях выше.

Тогда общее решение СЛОДУ имеет вид

\begin{equation*}
    x(t) = \sum_{k=1}^n C_k \psi_k(t).
\end{equation*}

\Proof

Так как $\psi'_k(t) = A\psi_k(t)$, то $\psi_k$ является решением.
А значит, в силу линейности множества решений, любая функция такого вида $x(t)$ является решением.

Покажем, что любое решение представимо в таком виде.
Обозначим $\hat{x}(t)$ -- произвольное решение; $x_0 \coloneqq \hat{x}(0)$.

Разложим $x_0$ по векторам Жорданового базиса: $x_0 = \sum_{k=1}^n C_k v_k$.
Тогда $x(t) \coloneqq \sum_{k=1}^n C_k \psi_k(t)$, которая является решением, как доказано ранее.

Из формул для $\psi_k$ очевидно, что $\psi_k(0) = v_k$.
А значит $x(0) = \sum C_k \psi_k(0) = \sum C_k v_k = x_0 = x(t)$.
По теореме Коши, $\hat{x} = x$, и мы представили произвольное решение в искомом виде.

\Endproof

\Theor{Об овеществлении решений}

Аналогично соответствующей теореме в простейшем случае, если собственные значения и Жордановы цепочки делятся на попарно комплексно сопряженные и вещественные, то общее решение можно записать в виде

\begin{equation*}
    x(t) = \sum_{k=1}^m \left( a_k \Re \left( \psi_k(t) \right) + b_k \Im \left( \psi_k(t) \right) \right) + \sum_{s=2m+1}^n c_s \psi_s(t),
\end{equation*}

где $a_k, b_k, c_k \in \R$.


