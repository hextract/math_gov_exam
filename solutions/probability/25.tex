\subsection{Неравенство Чебышева и закон больших чисел.}

\textbf{Неравенство Маркова.}
Если $\mathbb{E}|\xi| < \infty$, то для любого $x > 0$
\[
  \mathbb{P}(|\xi| \geq x) \leq \frac{\mathbb{E}|\xi|}{x}.
\]

\Proof

\Remind называем случайную величину $I$ индикатором события $A$, если $I=1$, если А произошло, а иначе $I=0$. Нужно помнить, что это Бернуллевская случайная величина, с
параметром (и матожиданием) $p = P(I(A) = 1) = P(A)$. Другой, важный для доказательства факт: $I(A) + I(\overline{A}) = 1$

\[
  |\xi| = |\xi| \cdot I(|\xi| < x) + |\xi| \cdot I(|\xi| \geq x) = |\xi| (I(|\xi| < x) + I(|\xi| \geq x)) \geq |\xi| \cdot I(|\xi| \geq x) \geq x \cdot I(|\xi| \geq x).
\]

В первом переходе к неравенству воспользуемся разложением по индикаторам, во втором — тем, что на событии $\{|\xi|\ge x\}$ выполнено $|\xi|\ge x$ (а вне его индикатор равен нулю).

Тогда $\mathbb{E}|\xi| \geq \mathbb{E}(x \cdot I(|\xi| \geq x)) = x \cdot \mathbb{P}(|\xi| \geq x)$.

Осталось разделить обе части этого неравенства на положительное число $x$.

\Endproof

\textbf{Неравенство Чебышева.}
Если существует $D\xi$, то $\forall \varepsilon > 0$ верно
\[
  \mathbb{P}(|\xi - \mathbb{E}\xi| \geq \varepsilon) \leq \frac{D\xi}{\varepsilon^2}.
\]

\Proof

Для $\varepsilon > 0$ неравенство $|\xi - \mathbb{E}\xi| \geq \varepsilon \iff (\xi - \mathbb{E}\xi)^2 \geq \varepsilon^2$,
поэтому
\[
  \mathbb{P}(|\xi - \mathbb{E}\xi| \geq \varepsilon)
  = \mathbb{P}((\xi - \mathbb{E}\xi)^2 \geq \varepsilon^2)
  \leq \frac{\mathbb{E}(\xi - \mathbb{E}\xi)^2}{\varepsilon^2}
  = \frac{D\xi}{\varepsilon^2}.
\]

Первый переход сделан по неравенству Маркова, второй по определению дисперсии

\Endproof

\textbf{Замечание.} \hyperlink{probability_convergence}{Определение сходимости по вероятности}

\textbf{Закон больших чисел (Чебышева)}
Для любой последовательности $\xi_1, \xi_2, \ldots$ попарно независимых и одинаково распределённых случайных величин с конечным вторым моментом $\mathbb{E}\xi_1^2 <
\infty$ имеет место сходимость
\[
  \frac{\xi_1 + \cdots + \xi_n}{n} \xrightarrow{p} \mathbb{E}\xi_1.
\]

\Proof

Обозначим через $S_n = \xi_1 + \cdots + \xi_n$ сумму первых $n$ случайных величин.
Из линейности матожидания получим
\[
  \mathbb{E}\left(\frac{S_n}{n}\right) = \frac{\mathbb{E}\xi_1 + \cdots + \mathbb{E}\xi_n}{n}
  = \frac{n\mathbb{E}\xi_1}{n} = \mathbb{E}\xi_1.
\]

Возьмем произвольное $\varepsilon > 0$. Воспользуемся неравенством Чебышёва:
\[
  \mathbb{P}\left(\left| \frac{S_n}{n} - \mathbb{E}\left(\frac{S_n}{n}\right) \right| \geq \varepsilon\right)
  \leq \frac{D\left(\frac{S_n}{n}\right)}{\varepsilon^2}
  = \frac{DS_n}{n^2 \varepsilon^2}
  = \frac{D\xi_1 + \cdots + D\xi_n}{n^2 \varepsilon^2}
\]
\[
  = \frac{n D\xi_1}{n^2 \varepsilon^2}
  = \frac{D\xi_1}{n \varepsilon^2}
  \longrightarrow_{n \to +\infty} 0,
\]

Все переходы по свойствам дисперсии.

\Endproof

\Consequence \textbf{(Закон больших чисел Бернулли)}

Пусть проводится $n$ независимых испытаний, в каждом из которых событие $A$ происходит с вероятностью $p$. Пусть $\nu_n$ — число наступлений события $A$ в $n$
испытаниях. Тогда относительная частота $\frac{\nu_n}{n}$ сходится по вероятности к $p$:
\[
  \frac{\nu_n}{n} \xrightarrow{p} p.
\]

\Proof

Введём индикаторы: $\xi_i = I(\text{событие } A \text{ произошло в } i\text{-м испытании})$. Тогда $\xi_i \sim Bern(p)$ — независимые одинаково распределённые случайные величины с
\[
  \mathbb{E}\xi_i = p, \quad D\xi_i = p(1-p).
\]

Число успехов $\nu_n = \xi_1 + \ldots + \xi_n$. По ЗБЧ Чебышева:
\[
  \frac{\nu_n}{n} = \frac{\xi_1 + \ldots + \xi_n}{n} \xrightarrow{p} \mathbb{E}\xi_1 = p.
\]

\Endproof

\textbf{Замечание.} Этот результат даёт теоретическое обоснование \textit{статистическому определению вероятности}: если провести много испытаний, частота события будет
близка к его вероятности.
